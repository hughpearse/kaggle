{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9UOcc4nnp1Pc",
    "outputId": "9bf385a8-91ee-4344-9e66-f7d064e0cf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1\n",
      "  Cloning https://github.com/keras-team/keras-tuner.git (to revision 1.0.2rc1) to /private/var/folders/jr/np4gp4_s0rn5j91v77mbv_540000gn/T/pip-req-build-k1ow017q\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
      "Processing /Users/hughpearse/Library/Caches/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94/future-0.18.2-py3-none-any.whl\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.1-cp36-cp36m-macosx_10_9_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 17.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Processing /Users/hughpearse/Library/Caches/pip/wheels/86/1b/58/c23af2fe683acd8edc15d5a1268f0242be1ff2cf827fe34737/terminaltables-3.1.0-py3-none-any.whl\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.48.0-py2.py3-none-any.whl (67 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.5.2-cp36-cp36m-macosx_10_9_x86_64.whl (28.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.8 MB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp36-cp36m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 12.5 MB/s eta 0:00:01     |████████████████                | 3.6 MB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: keras-tuner\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/jr/np4gp4_s0rn5j91v77mbv_540000gn/T/pip-req-build-k1ow017q/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/jr/np4gp4_s0rn5j91v77mbv_540000gn/T/pip-req-build-k1ow017q/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/jr/np4gp4_s0rn5j91v77mbv_540000gn/T/pip-wheel-feo4bz1g\n",
      "       cwd: /private/var/folders/jr/np4gp4_s0rn5j91v77mbv_540000gn/T/pip-req-build-k1ow017q/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for keras-tuner\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for keras-tuner\n",
      "Failed to build keras-tuner\n",
      "\u001b[33mDEPRECATION: Could not build wheels for keras-tuner which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
      "Installing collected packages: pyparsing, six, packaging, future, numpy, tabulate, terminaltables, colorama, tqdm, idna, certifi, chardet, urllib3, requests, scipy, joblib, threadpoolctl, scikit-learn, keras-tuner\n",
      "    Running setup.py install for keras-tuner ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed certifi-2020.6.20 chardet-3.0.4 colorama-0.4.3 future-0.18.2 idna-2.10 joblib-0.16.0 keras-tuner numpy-1.19.1 packaging-20.4 pyparsing-2.4.7 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.2 six-1.15.0 tabulate-0.8.7 terminaltables-3.1.0 threadpoolctl-2.1.0 tqdm-4.48.0 urllib3-1.25.10\n",
      "Collecting autokeras==1.0.5\n",
      "  Using cached autokeras-1.0.5-py3-none-any.whl (84 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.0-cp36-cp36m-macosx_10_9_x86_64.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow>=2.3.0\n",
      "  Using cached tensorflow-2.3.0-cp36-cp36m-macosx_10_11_x86_64.whl (165.1 MB)\n",
      "Requirement already satisfied: numpy in ./sandbox/lib/python3.6/site-packages (from autokeras==1.0.5) (1.19.1)\n",
      "Requirement already satisfied: packaging in ./sandbox/lib/python3.6/site-packages (from autokeras==1.0.5) (20.4)\n",
      "Requirement already satisfied: scikit-learn in ./sandbox/lib/python3.6/site-packages (from autokeras==1.0.5) (0.23.1)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.12.2-cp36-cp36m-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp36-cp36m-macosx_10_6_intel.whl (28.5 MB)\n",
      "Processing /Users/hughpearse/Library/Caches/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63/wrapt-1.12.1-py3-none-any.whl\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Processing /Users/hughpearse/Library/Caches/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Using cached tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Processing /Users/hughpearse/Library/Caches/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679/absl_py-0.9.0-py3-none-any.whl\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.30.0-cp36-cp36m-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./sandbox/lib/python3.6/site-packages (from tensorflow>=2.3.0->autokeras==1.0.5) (1.15.0)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in ./sandbox/lib/python3.6/site-packages (from tensorflow>=2.3.0->autokeras==1.0.5) (0.34.2)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-macosx_10_6_intel.whl (3.0 MB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./sandbox/lib/python3.6/site-packages (from packaging->autokeras==1.0.5) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in ./sandbox/lib/python3.6/site-packages (from scikit-learn->autokeras==1.0.5) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./sandbox/lib/python3.6/site-packages (from scikit-learn->autokeras==1.0.5) (2.1.0)\n",
      "Requirement already satisfied: setuptools in ./sandbox/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras==1.0.5) (49.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./sandbox/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.5) (2.24.0)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.20.0-py2.py3-none-any.whl (91 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.2.2-py3-none-any.whl (88 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./sandbox/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.5) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./sandbox/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./sandbox/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./sandbox/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras==1.0.5) (2020.6.20)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Using cached rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Installing collected packages: python-dateutil, pytz, pandas, protobuf, scipy, wrapt, astunparse, termcolor, werkzeug, absl-py, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, grpcio, zipp, importlib-metadata, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, tensorboard, keras-preprocessing, opt-einsum, google-pasta, gast, h5py, tensorflow-estimator, tensorflow, autokeras\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 autokeras-1.0.5 cachetools-4.1.1 gast-0.3.3 google-auth-1.20.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.30.0 h5py-2.10.0 importlib-metadata-1.7.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.3.0 pandas-1.1.0 protobuf-3.12.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 python-dateutil-2.8.1 pytz-2020.1 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1\n",
    "!pip install autokeras==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrQfA8v8peIP"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b87eaecf15b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautokeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "Cd_5Xtuqpmpm",
    "outputId": "ac587219-8455-496d-d875-63ab03267ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "PGASvRn6poKp",
    "outputId": "5b7342ac-8442-418d-b414-c059ecad0fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 23m 58s]\n",
      "val_loss: 0.0419795848429203\n",
      "\n",
      "Best val_loss So Far: 0.0419795848429203\n",
      "Total elapsed time: 00h 23m 58s\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter      |Value     |Best Value So Far   \n",
      "image_block_1/block_type|resnet    |vanilla             \n",
      "image_block_1/normalize|True      |True                \n",
      "image_block_1/augment|True      |False               \n",
      "image_block_1/image_augmentation_1/horizontal_flip|True      |None                \n",
      "image_block_1/image_augmentation_1/vertical_flip|False     |None                \n",
      "image_block_1/image_augmentation_1/contrast_factor|0.0       |None                \n",
      "image_block_1/image_augmentation_1/rotation_factor|0.0       |None                \n",
      "image_block_1/image_augmentation_1/translation_factor|0.1       |None                \n",
      "image_block_1/image_augmentation_1/zoom_factor|0.0       |None                \n",
      "image_block_1/res_net_block_1/pretrained|True      |None                \n",
      "image_block_1/res_net_block_1/version|resnet50  |None                \n",
      "image_block_1/res_net_block_1/trainable|True      |None                \n",
      "image_block_1/res_net_block_1/imagenet_size|True      |None                \n",
      "classification_head_1/spatial_reduction_1/reduction_type|global_avg|flatten             \n",
      "classification_head_1/dropout|0         |0.5                 \n",
      "optimizer           |adam      |adam                \n",
      "learning_rate       |1e-05     |0.001               \n",
      "\n",
      "Epoch 1/10\n",
      "  23/1500 [..............................] - ETA: 8:42:14 - loss: 2.1283 - accuracy: 0.2337"
     ]
    }
   ],
   "source": [
    "# Initialize the ImageClassifier.\n",
    "clf = ak.ImageClassifier(max_trials=3)\n",
    "# Search for the best model.\n",
    "clf.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRHY9Q-Kpq_L"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the testing data.\n",
    "print('Accuracy: {accuracy}'.format(\n",
    "    accuracy=clf.evaluate(x_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "digits.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
