{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Assign X and Y from training data\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "y_train = train[\"label\"].values\n",
    "\n",
    "# Normalize the data for better performance\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# create validation dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 279,242\n",
      "Trainable params: 278,666\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range = 0.10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1)\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64\n",
    "batches = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/459 [..............................] - ETA: 0s - loss: 2.4202 - accuracy: 0.0469WARNING:tensorflow:From /Users/hughpearse/Downloads/kaggle/digit-recognizer/sandbox/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "459/459 [==============================] - 66s 145ms/step - loss: 0.2993 - accuracy: 0.9055 - val_loss: 0.4734 - val_accuracy: 0.8515\n",
      "Epoch 2/50\n",
      "459/459 [==============================] - 61s 134ms/step - loss: 0.1062 - accuracy: 0.9684 - val_loss: 0.1120 - val_accuracy: 0.9661\n",
      "Epoch 3/50\n",
      "459/459 [==============================] - 65s 141ms/step - loss: 0.0809 - accuracy: 0.9771 - val_loss: 0.1019 - val_accuracy: 0.9694\n",
      "Epoch 4/50\n",
      "459/459 [==============================] - 143s 312ms/step - loss: 0.0717 - accuracy: 0.9793 - val_loss: 0.0826 - val_accuracy: 0.9749\n",
      "Epoch 5/50\n",
      "459/459 [==============================] - 172s 374ms/step - loss: 0.0630 - accuracy: 0.9821 - val_loss: 0.0619 - val_accuracy: 0.9826\n",
      "Epoch 6/50\n",
      "459/459 [==============================] - 165s 360ms/step - loss: 0.0572 - accuracy: 0.9838 - val_loss: 0.1522 - val_accuracy: 0.9584\n",
      "Epoch 7/50\n",
      "459/459 [==============================] - 152s 331ms/step - loss: 0.0561 - accuracy: 0.9830 - val_loss: 0.0685 - val_accuracy: 0.9797\n",
      "Epoch 8/50\n",
      "459/459 [==============================] - 154s 335ms/step - loss: 0.0529 - accuracy: 0.9841 - val_loss: 0.0471 - val_accuracy: 0.9859\n",
      "Epoch 9/50\n",
      "459/459 [==============================] - 154s 336ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.0783 - val_accuracy: 0.9763\n",
      "Epoch 10/50\n",
      "459/459 [==============================] - 79s 173ms/step - loss: 0.0477 - accuracy: 0.9858 - val_loss: 0.0600 - val_accuracy: 0.9829\n",
      "Epoch 11/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9882\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "459/459 [==============================] - 78s 170ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0637 - val_accuracy: 0.9837\n",
      "Epoch 12/50\n",
      "459/459 [==============================] - 74s 161ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 0.0359 - val_accuracy: 0.9905\n",
      "Epoch 13/50\n",
      "459/459 [==============================] - 62s 135ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0444 - val_accuracy: 0.9875\n",
      "Epoch 14/50\n",
      "459/459 [==============================] - 64s 140ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0307 - val_accuracy: 0.9909\n",
      "Epoch 15/50\n",
      "459/459 [==============================] - 70s 152ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.0366 - val_accuracy: 0.9902\n",
      "Epoch 16/50\n",
      "459/459 [==============================] - 69s 150ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0397 - val_accuracy: 0.9890\n",
      "Epoch 17/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9918\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "459/459 [==============================] - 72s 158ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0352 - val_accuracy: 0.9905\n",
      "Epoch 18/50\n",
      "459/459 [==============================] - 70s 152ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0351 - val_accuracy: 0.9915\n",
      "Epoch 19/50\n",
      "459/459 [==============================] - 63s 136ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.0344 - val_accuracy: 0.9908\n",
      "Epoch 20/50\n",
      "459/459 [==============================] - 62s 136ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0290 - val_accuracy: 0.9921\n",
      "Epoch 21/50\n",
      "459/459 [==============================] - 63s 137ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0360 - val_accuracy: 0.9916\n",
      "Epoch 22/50\n",
      "459/459 [==============================] - 63s 137ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0316 - val_accuracy: 0.9921\n",
      "Epoch 23/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9958\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "459/459 [==============================] - 63s 137ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0319 - val_accuracy: 0.9915\n",
      "Epoch 24/50\n",
      "459/459 [==============================] - 64s 140ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0296 - val_accuracy: 0.9923\n",
      "Epoch 25/50\n",
      "459/459 [==============================] - 63s 137ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0334 - val_accuracy: 0.9917\n",
      "Epoch 26/50\n",
      "459/459 [==============================] - 63s 138ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0289 - val_accuracy: 0.9925\n",
      "Epoch 27/50\n",
      "459/459 [==============================] - 63s 137ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0318 - val_accuracy: 0.9924\n",
      "Epoch 28/50\n",
      "459/459 [==============================] - 62s 136ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.0315 - val_accuracy: 0.9915\n",
      "Epoch 29/50\n",
      "459/459 [==============================] - 63s 136ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0258 - val_accuracy: 0.9936\n",
      "Epoch 30/50\n",
      "459/459 [==============================] - 63s 137ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0285 - val_accuracy: 0.9933\n",
      "Epoch 31/50\n",
      "459/459 [==============================] - 64s 140ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 32/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "459/459 [==============================] - 61s 133ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0295 - val_accuracy: 0.9930\n",
      "Epoch 33/50\n",
      "459/459 [==============================] - 60s 131ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0314 - val_accuracy: 0.9919\n",
      "Epoch 34/50\n",
      "459/459 [==============================] - 55s 120ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0295 - val_accuracy: 0.9933\n",
      "Epoch 35/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "459/459 [==============================] - 53s 115ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0294 - val_accuracy: 0.9928\n",
      "Epoch 36/50\n",
      "459/459 [==============================] - 54s 117ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
      "Epoch 37/50\n",
      "459/459 [==============================] - 54s 119ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0285 - val_accuracy: 0.9940\n",
      "Epoch 38/50\n",
      "459/459 [==============================] - 54s 117ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0282 - val_accuracy: 0.9929\n",
      "Epoch 39/50\n",
      "459/459 [==============================] - 54s 117ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0308 - val_accuracy: 0.9925\n",
      "Epoch 40/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "459/459 [==============================] - 54s 117ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0273 - val_accuracy: 0.9938\n",
      "Epoch 41/50\n",
      "459/459 [==============================] - 54s 118ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0325 - val_accuracy: 0.9932\n",
      "Epoch 42/50\n",
      "459/459 [==============================] - 54s 117ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0304 - val_accuracy: 0.9933\n",
      "Epoch 43/50\n",
      "459/459 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "459/459 [==============================] - 54s 117ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0286 - val_accuracy: 0.9932\n",
      "Epoch 44/50\n",
      "459/459 [==============================] - 60s 131ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.9933\n",
      "Epoch 45/50\n",
      "459/459 [==============================] - 60s 131ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0277 - val_accuracy: 0.9930\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 60s 130ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0291 - val_accuracy: 0.9930\n",
      "Epoch 47/50\n",
      "459/459 [==============================] - 60s 132ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0270 - val_accuracy: 0.9938\n",
      "Epoch 48/50\n",
      "459/459 [==============================] - 60s 130ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0311 - val_accuracy: 0.9935\n",
      "Epoch 49/50\n",
      "459/459 [==============================] - 60s 132ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0273 - val_accuracy: 0.9934\n",
      "Epoch 50/50\n",
      "459/459 [==============================] - 62s 134ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0303 - val_accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs\"\n",
    "!rm -rf ./{logdir}\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "# Set a learning rate annealer\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    batches,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_data=val_batches,\n",
    "    callbacks=[reduce_lr, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8809), started 1 day, 0:21:40 ago. (Use '!kill 8809' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6165b1864377f10b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6165b1864377f10b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
