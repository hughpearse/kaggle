{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Assign X and Y from training data\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "y_train = train[\"label\"].values\n",
    "\n",
    "# Normalize the data for better performance\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_103 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 1, 1, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 397,130\n",
      "Trainable params: 396,298\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, kernel_size=(4, 4), activation=\"relu\", strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "batch_size = 150\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range = 0.10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10)\n",
    "batches = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 17s 220ms/step - loss: 0.0257 - accuracy: 0.9930 - val_loss: 0.0380 - val_accuracy: 0.9886\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 18s 223ms/step - loss: 0.0889 - accuracy: 0.9751 - val_loss: 0.0724 - val_accuracy: 0.9788\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 18s 223ms/step - loss: 0.0369 - accuracy: 0.9900 - val_loss: 0.0352 - val_accuracy: 0.9894\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 18s 222ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.0189 - val_accuracy: 0.9924\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 20s 248ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.0459 - val_accuracy: 0.9871\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 21s 266ms/step - loss: 0.0268 - accuracy: 0.9924 - val_loss: 0.0261 - val_accuracy: 0.9917\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9942\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "79/79 [==============================] - 22s 277ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0285 - val_accuracy: 0.9924\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 22s 280ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0231 - val_accuracy: 0.9917\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 20s 249ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0137 - val_accuracy: 0.9962\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 0.0268 - val_accuracy: 0.9932\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 18s 234ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0285 - val_accuracy: 0.9901\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9958\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "79/79 [==============================] - 20s 256ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0186 - val_accuracy: 0.9954\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 19s 243ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0125 - val_accuracy: 0.9962\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 20s 252ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0209 - val_accuracy: 0.9932\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9959\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "79/79 [==============================] - 19s 245ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0245 - val_accuracy: 0.9917\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 21s 263ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0121 - val_accuracy: 0.9939\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0191 - val_accuracy: 0.9954\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9962\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0113 - val_accuracy: 0.9954\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 18s 231ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0171 - val_accuracy: 0.9939\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0123 - val_accuracy: 0.9954\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0152 - val_accuracy: 0.9939\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 20s 250ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 18s 233ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0113 - val_accuracy: 0.9970\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 22s 278ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0075 - val_accuracy: 0.9985\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 20s 247ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0096 - val_accuracy: 0.9954\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 18s 234ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0102 - val_accuracy: 0.9962\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9974\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "79/79 [==============================] - 19s 240ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0152 - val_accuracy: 0.9939\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0088 - val_accuracy: 0.9962\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 18s 232ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0128 - val_accuracy: 0.9954\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "79/79 [==============================] - 19s 242ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0056 - val_accuracy: 0.9977\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 19s 242ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 20s 247ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0134 - val_accuracy: 0.9947\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0049 - val_accuracy: 0.9977\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 19s 236ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0097 - val_accuracy: 0.9970\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0148 - val_accuracy: 0.9947\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 19s 240ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0102 - val_accuracy: 0.9962\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 19s 244ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0074 - val_accuracy: 0.9970\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 19s 237ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0185 - val_accuracy: 0.9932\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0120 - val_accuracy: 0.9962\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 21s 262ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0104 - val_accuracy: 0.9962\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0124 - val_accuracy: 0.9954\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 18s 234ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 18s 233ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0170 - val_accuracy: 0.9962\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0157 - val_accuracy: 0.9947\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 20s 253ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0124 - val_accuracy: 0.9947\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0089 - val_accuracy: 0.9970\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 20s 257ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 18s 234ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0062 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "# Set a learning rate annealer\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001)\n",
    "history = model.fit(\n",
    "    batches,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    validation_data=val_batches,\n",
    "    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
